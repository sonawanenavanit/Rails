{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "groq_api_key= os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]=os.getenv(\"HF_TOKEN\")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings =HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://docs.python.org/3.13/whatsnew/3.13.html\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"document\",\"related\",\"sphinxsidebar\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7f04ea5eacf0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "splits=text_splitter.split_documents(docs)\n",
    "vectorestore = Chroma.from_documents(documents=splits,embedding=embeddings)\n",
    "retriever = vectorestore.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering task\"\n",
    "    \"Use the following pieces of retrived context to answer\"\n",
    "    \"the question. If you don't know the answer, say that you\"\n",
    "    \"don't know. Use three sentences maximum and keep the\"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain=create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain=create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the new feature?',\n",
       " 'context': [Document(metadata={'source': 'https://docs.python.org/3.13/whatsnew/3.13.html'}, page_content='Navigation\\n\\n\\nindex\\n\\nmodules |\\n\\nnext |\\n\\nprevious |\\n\\nPython »\\n\\n\\n\\n\\n\\n\\n\\n3.13.0b4 Documentation »\\n    \\nWhat’s New in Python »\\nWhat’s New In Python 3.13\\n\\n\\n\\n\\n\\n\\n\\n                     |\\n                \\n\\n\\n    Theme\\n    \\nAuto\\nLight\\nDark\\n\\n |\\n\\n\\n\\n\\n\\n\\nWhat’s New In Python 3.13¶\\n\\nEditor:\\nThomas Wouters\\n\\n\\nThis article explains the new features in Python 3.13, compared to 3.12.\\nFor full details, see the changelog.\\n\\nSee also\\nPEP 719 – Python 3.13 Release Schedule\\n\\n\\nNote\\nPrerelease users should be aware that this document is currently in draft\\nform. It will be updated substantially as Python 3.13 moves towards release,\\nso it’s worth checking back even after reading earlier versions.'),\n",
       "  Document(metadata={'source': 'https://docs.python.org/3.13/whatsnew/3.13.html'}, page_content='Navigation\\n\\n\\nindex\\n\\nmodules |\\n\\nnext |\\n\\nprevious |\\n\\nPython »\\n\\n\\n\\n\\n\\n\\n\\n3.13.0b4 Documentation »\\n    \\nWhat’s New in Python »\\nWhat’s New In Python 3.13\\n\\n\\n\\n\\n\\n\\n\\n                     |\\n                \\n\\n\\n    Theme\\n    \\nAuto\\nLight\\nDark\\n\\n |\\n\\n\\n\\n\\n\\n\\nWhat’s New In Python 3.13¶\\n\\nEditor:\\nThomas Wouters\\n\\n\\nThis article explains the new features in Python 3.13, compared to 3.12.\\nFor full details, see the changelog.\\n\\nSee also\\nPEP 719 – Python 3.13 Release Schedule\\n\\n\\nNote\\nPrerelease users should be aware that this document is currently in draft\\nform. It will be updated substantially as Python 3.13 moves towards release,\\nso it’s worth checking back even after reading earlier versions.'),\n",
       "  Document(metadata={'source': 'https://docs.python.org/3.13/whatsnew/3.13.html'}, page_content='Navigation\\n\\n\\nindex\\n\\nmodules |\\n\\nnext |\\n\\nprevious |\\n\\nPython »\\n\\n\\n\\n\\n\\n\\n\\n3.13.0b4 Documentation »\\n    \\nWhat’s New in Python »\\nWhat’s New In Python 3.13\\n\\n\\n\\n\\n\\n\\n\\n                     |\\n                \\n\\n\\n    Theme\\n    \\nAuto\\nLight\\nDark\\n\\n |\\n\\n\\n\\n\\n\\n\\nWhat’s New In Python 3.13¶\\n\\nEditor:\\nThomas Wouters\\n\\n\\nThis article explains the new features in Python 3.13, compared to 3.12.\\nFor full details, see the changelog.\\n\\nSee also\\nPEP 719 – Python 3.13 Release Schedule\\n\\n\\nNote\\nPrerelease users should be aware that this document is currently in draft\\nform. It will be updated substantially as Python 3.13 moves towards release,\\nso it’s worth checking back even after reading earlier versions.'),\n",
       "  Document(metadata={'source': 'https://docs.python.org/3.13/whatsnew/3.13.html'}, page_content='Navigation\\n\\n\\nindex\\n\\nmodules |\\n\\nnext |\\n\\nprevious |\\n\\nPython »\\n\\n\\n\\n\\n\\n\\n\\n3.13.0b4 Documentation »\\n    \\nWhat’s New in Python »\\nWhat’s New In Python 3.13\\n\\n\\n\\n\\n\\n\\n\\n                     |\\n                \\n\\n\\n    Theme\\n    \\nAuto\\nLight\\nDark\\n\\n |\\n\\n\\n\\n\\n\\n\\nWhat’s New In Python 3.13¶\\n\\nEditor:\\nThomas Wouters\\n\\n\\nThis article explains the new features in Python 3.13, compared to 3.12.\\nFor full details, see the changelog.\\n\\nSee also\\nPEP 719 – Python 3.13 Release Schedule\\n\\n\\nNote\\nPrerelease users should be aware that this document is currently in draft\\nform. It will be updated substantially as Python 3.13 moves towards release,\\nso it’s worth checking back even after reading earlier versions.')],\n",
       " 'answer': \"I don't know.\"}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\":\"What are the new feature?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How it handles garbege collection?',\n",
       " 'context': [Document(metadata={'source': 'https://docs.python.org/3.13/whatsnew/3.13.html'}, page_content='gc¶\\n\\nThe cyclic garbage collector is now incremental, which changes the meanings\\nof the results of gc.get_threshold() and gc.set_threshold() as\\nwell as gc.get_count() and gc.get_stats().\\n\\ngc.get_threshold() returns a three-item tuple for backwards compatibility.\\nThe first value is the threshold for young collections, as before; the second\\nvalue determines the rate at which the old collection is scanned (the\\ndefault is 10, and higher values mean that the old collection is scanned more slowly).\\nThe third value is meaningless and is always zero.\\ngc.set_threshold() ignores any items after the second.\\ngc.get_count() and gc.get_stats()\\nreturn the same format of results as before.\\nThe only difference is that instead of the results referring to\\nthe young, aging and old generations, the results refer to the\\nyoung generation and the aging and collecting spaces of the old generation.'),\n",
       "  Document(metadata={'source': 'https://docs.python.org/3.13/whatsnew/3.13.html'}, page_content='gc¶\\n\\nThe cyclic garbage collector is now incremental, which changes the meanings\\nof the results of gc.get_threshold() and gc.set_threshold() as\\nwell as gc.get_count() and gc.get_stats().\\n\\ngc.get_threshold() returns a three-item tuple for backwards compatibility.\\nThe first value is the threshold for young collections, as before; the second\\nvalue determines the rate at which the old collection is scanned (the\\ndefault is 10, and higher values mean that the old collection is scanned more slowly).\\nThe third value is meaningless and is always zero.\\ngc.set_threshold() ignores any items after the second.\\ngc.get_count() and gc.get_stats()\\nreturn the same format of results as before.\\nThe only difference is that instead of the results referring to\\nthe young, aging and old generations, the results refer to the\\nyoung generation and the aging and collecting spaces of the old generation.'),\n",
       "  Document(metadata={'source': 'https://docs.python.org/3.13/whatsnew/3.13.html'}, page_content='gc¶\\n\\nThe cyclic garbage collector is now incremental, which changes the meanings\\nof the results of gc.get_threshold() and gc.set_threshold() as\\nwell as gc.get_count() and gc.get_stats().\\n\\ngc.get_threshold() returns a three-item tuple for backwards compatibility.\\nThe first value is the threshold for young collections, as before; the second\\nvalue determines the rate at which the old collection is scanned (the\\ndefault is 10, and higher values mean that the old collection is scanned more slowly).\\nThe third value is meaningless and is always zero.\\ngc.set_threshold() ignores any items after the second.\\ngc.get_count() and gc.get_stats()\\nreturn the same format of results as before.\\nThe only difference is that instead of the results referring to\\nthe young, aging and old generations, the results refer to the\\nyoung generation and the aging and collecting spaces of the old generation.'),\n",
       "  Document(metadata={'source': 'https://docs.python.org/3.13/whatsnew/3.13.html'}, page_content='gc¶\\n\\nThe cyclic garbage collector is now incremental, which changes the meanings\\nof the results of gc.get_threshold() and gc.set_threshold() as\\nwell as gc.get_count() and gc.get_stats().\\n\\ngc.get_threshold() returns a three-item tuple for backwards compatibility.\\nThe first value is the threshold for young collections, as before; the second\\nvalue determines the rate at which the old collection is scanned (the\\ndefault is 10, and higher values mean that the old collection is scanned more slowly).\\nThe third value is meaningless and is always zero.\\ngc.set_threshold() ignores any items after the second.\\ngc.get_count() and gc.get_stats()\\nreturn the same format of results as before.\\nThe only difference is that instead of the results referring to\\nthe young, aging and old generations, the results refer to the\\nyoung generation and the aging and collecting spaces of the old generation.')],\n",
       " 'answer': 'The cyclic garbage collector is now incremental, which changes the meanings of the results of gc.get_threshold() and gc.set_threshold() as well as gc.get_count() and gc.get_stats().'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\":\"How it handles garbege collection?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Chat History\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"\"\"\n",
    "    Given a chat history and the latest user question\n",
    "    which might reference context in the chat history,\n",
    "    formulate a standalone question which can be understood\n",
    "    without the chat history. Do NOT answer the question,\n",
    "    just reformulation it if needed and otherwise return it as is.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7f04ea5eacf0>))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='\\n    Given a chat history and the latest user question\\n    which might reference context in the chat history,\\n    formulate a standalone question which can be understood\\n    without the chat history. Do NOT answer the question,\\n    just reformulation it if needed and otherwise return it as is.\\n    ')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7f0514560d40>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7f0514563440>, model_name='Llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7f04ea5eacf0>)), config={'run_name': 'chat_retriever_chain'})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retriver=create_history_aware_retriever(llm,retriever,contextualize_q_prompt)\n",
    "history_aware_retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_answer_chain= create_stuff_documents_chain(llm,qa_prompt)\n",
    "question_answer_chain= create_stuff_documents_chain(llm,qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriver,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The garbage collector is a mechanism that periodically reclaims memory occupied by objects that are no longer needed or referenced in a program.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "chat_history=[]\n",
    "question = \"What is the garbage collection\"\n",
    "response1=rag_chain.invoke({\"input\":question,\"chat_history\":chat_history})\n",
    "\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=response[\"answer\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "question2=\"Tell me more about it?\"\n",
    "response2 = rag_chain.invoke({\"input\":question,\"chat_history\":chat_history})\n",
    "print(response2['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is the garbage collection'),\n",
       " AIMessage(content=\"I don't know.\")]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
